model:
  class_path: rslearn.train.lightning_module.RslearnLightningModule
  init_args:
    model:
      class_path: rslearn.models.multitask.MultiTaskModel
      init_args:
        encoder:
          - class_path: rslp.helios.model.Helios
            init_args:
              checkpoint_path: "{CHECKPOINT_PATH}"
              selector: ["encoder"]
              forward_kwargs:
                patch_size: {PATCH_SIZE}
        decoders:
          eurosat:
            - class_path: rslearn.models.pooling_decoder.PoolingDecoder
              init_args:
                in_channels: {ENCODER_EMBEDDING_SIZE}
                num_conv_layers: 1
                num_fc_layers: 1
                out_channels: 10
            - class_path: rslearn.train.tasks.classification.ClassificationHead
    lr: 0.0001
    plateau: true
    plateau_factor: 0.2
    plateau_patience: 2
    plateau_min_lr: 0
    plateau_cooldown: 10
data:
  class_path: rslearn.train.data_module.RslearnDataModule
  init_args:
    path: /weka/dfive-default/rslearn-eai/datasets/eurosat/rslearn_dataset
    inputs:
      sentinel2_l2a:
        data_type: "raster"
        layers: ["sentinel2"]
        bands: ["B02", "B03", "B04", "B08", "B05", "B06", "B07", "B8A", "B11", "B12", "B01", "B09"]
        passthrough: true
      # Include gse here so it's a required layer, even though we don't actually need it.
      # This way we match the windows that gse.yaml model will train/validate on.
      gse_ignored:
        data_type: "raster"
        layers: ["gse"]
        bands: ["A00", "A01", "A02", "A03", "A04", "A05", "A06", "A07", "A08", "A09", "A10", "A11", "A12", "A13", "A14", "A15", "A16", "A17", "A18", "A19", "A20", "A21", "A22", "A23", "A24", "A25", "A26", "A27", "A28", "A29", "A30", "A31", "A32", "A33", "A34", "A35", "A36", "A37", "A38", "A39", "A40", "A41", "A42", "A43", "A44", "A45", "A46", "A47", "A48", "A49", "A50", "A51", "A52", "A53", "A54", "A55", "A56", "A57", "A58", "A59", "A60", "A61", "A62", "A63"]
        passthrough: true
      label:
        data_type: "vector"
        layers: ["label"]
        is_target: true
    task:
      class_path: rslearn.train.tasks.multi_task.MultiTask
      init_args:
        tasks:
          eurosat:
            class_path: rslearn.train.tasks.classification.ClassificationTask
            init_args:
              property_name: "category"
              classes: ["AnnualCrop", "Forest", "HerbaceousVegetation", "Highway", "Industrial", "Pasture", "PermanentCrop", "Residential", "River", "SeaLake"]
              enable_f1_metric: true
              metric_kwargs:
                average: "micro"
        input_mapping:
          eurosat:
            label: "targets"
    batch_size: 16
    num_workers: 32
    default_config:
      transforms:
        - class_path: rslp.helios.norm.HeliosNormalize
          init_args:
            config_fname: "/opt/helios/data/norm_configs/computed.json"
            band_names:
              sentinel2_l2a: ["B02", "B03", "B04", "B08", "B05", "B06", "B07", "B8A", "B11", "B12", "B01", "B09"]
    train_config:
      tags:
        split: "train"
    val_config:
      tags:
        split: "val"
    test_config:
      tags:
        split: "val"
trainer:
  max_epochs: 100
  callbacks:
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: "epoch"
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        save_top_k: 1
        save_last: true
        monitor: val_loss
        mode: min
    - class_path: rslearn.train.callbacks.freeze_unfreeze.FreezeUnfreeze
      init_args:
        module_selector: ["model", "encoder", 0]
        unfreeze_at_epoch: 20
        unfreeze_lr_factor: 10
rslp_project: placeholder
rslp_experiment: placeholder
