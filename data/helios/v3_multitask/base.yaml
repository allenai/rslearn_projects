model:
  class_path: rslearn.train.lightning_module.RslearnLightningModule
  init_args:
    model:
      class_path: rslearn.models.multitask.MultiTaskModel
      init_args:
        encoder:
          - class_path: rslp.helios.model.Helios
            init_args:
              checkpoint_path: "{CHECKPOINT_PATH}"
              selector: ["encoder"]
              forward_kwargs:
                patch_size: {PATCH_SIZE}
        decoders:  # Filled in by make_multidataset_config.py
        lazy_decode: true
    lr: 0.0001
    scheduler:
      class_path: rslearn.train.scheduler.CosineAnnealingScheduler
      init_args:
        T_max: 150
        eta_min: 0

data:
  class_path: rslearn.train.data_module.MultiDatasetDataModule
  init_args:
    round_robin: true
    refill_batches: true
    num_workers: 16
    data_modules:  # Filled in by make_multidataset_config.py

trainer:
  max_epochs: 100
  callbacks:
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: "epoch"
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        save_top_k: 1
        save_last: true
        monitor: val_loss
        mode: min
    - class_path: rslearn.train.callbacks.freeze_unfreeze.FreezeUnfreeze
      init_args:
        module_selector: ["model", "encoder", 0]
        unfreeze_at_epoch: 2

rslp_project: placeholder
rslp_experiment: placeholder
